{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn to classify\n",
    "\n",
    "Sample using scikit-learn \"Machine Learning in Python\" to create efficient MAV code.\n",
    "\n",
    "In this example a simple color classifier is learned from sample data.\n",
    "The function \"create_mask\" creates masks for test images automaticaly\n",
    "using HSV color filtering.\n",
    "\n",
    "Add some images to the data folder.\n",
    " - Image file names should end with .jpg and be in the folder \"test_footage\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from random import randrange\n",
    "\n",
    "#function for manual labeling of data images\n",
    "def labeling(input_image):\n",
    "    img = input_image.copy()\n",
    "    pt1 = None; pt2 = None\n",
    "    \n",
    "    # Define a callback function for mouse events\n",
    "    def draw_rectangle(event, x, y, flags, params):\n",
    "        nonlocal pt1, pt2\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            pt1 = (x, y)#fix pt1\n",
    "            pt2 = (x, y)#initial value for pt2\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            pt2 = (x, y)#updating pt2 as we move the cursor\n",
    "            cv2.rectangle(img, pt1, pt2, (255, 255, 255), -1)\n",
    "            cv2.imshow('Input Image', img)\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "                pt2 = (x, y)#fix pt2\n",
    "                img_copy = img.copy()\n",
    "                cv2.rectangle(img_copy, pt1, pt2, (255, 255, 255), -1)\n",
    "                cv2.imshow('Input Image', img_copy)\n",
    "\n",
    "    # Create a window to display the input image\n",
    "    cv2.namedWindow('Input Image')\n",
    "\n",
    "    # Set the callback function for mouse events\n",
    "    cv2.setMouseCallback('Input Image', draw_rectangle)\n",
    "\n",
    "    # Display the input image and wait for the user to draw a rectangle\n",
    "    cv2.imshow('Input Image', img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Create a black and white mask image with the same dimensions as the input image\n",
    "    mask = np.zeros_like(input_image)\n",
    "    cv2.rectangle(mask, pt1, pt2, (255, 255, 255), -1)\n",
    "\n",
    "    # Destroy all windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Return the resulting black and white mask image\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a black and white image which is white where the obstacles is found\n",
    "#(based on color filtering in HSV)\n",
    "\n",
    "def create_mask(image, color):\n",
    "    image = cv2.imread(image)#creating an numpy array from the image\n",
    "    #crop the image to only have the horizon left\n",
    "    image = image[:, 80:180]\n",
    "    \n",
    "    #convert to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define the HSV range for each color\n",
    "    if (color == \"orange\"):\n",
    "        lower = np.array([0, 100, 100])\n",
    "        upper = np.array([25, 255, 255])\n",
    "    elif (color == \"green\"):\n",
    "        lower = np.array([35, 80, 40])\n",
    "        upper = np.array([70, 255, 100])\n",
    "    elif (color == \"white\"):\n",
    "        lower = np.array([0, 0, 100])\n",
    "        upper = np.array([150, 40, 240])\n",
    "        \n",
    "    elif (color == \"black\"):\n",
    "        lower = np.array([0, 0, 50])\n",
    "        upper = np.array([125, 150, 125])\n",
    "    else:#in case there is no one color for the obstacle, we can create the labels by hand\n",
    "        result = labeling(image)#choose the zone where the obstacle is on the image\n",
    "        cv2.destroyAllWindows()\n",
    "        return result, image\n",
    "    \n",
    "    # Create and apply the mask to the image to create the mask image\n",
    "    mask = cv2.inRange(hsv_image, lower, upper) #create mask\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)#apply mask\n",
    "    result = cv2.threshold(result[:,:,2], 1, 255, cv2.THRESH_BINARY)[1] #either white or black\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)#convert back to rgb\n",
    "    \n",
    "    return result, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#####FETCH THE IMAGES###################\n",
    "images_string = glob.glob(\"test_footage/*.jpg\")\n",
    "     \n",
    "print(len(images_string))#check to see if it worked\n",
    "print(type(images_string[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n",
      "(520, 240, 3)\n"
     ]
    }
   ],
   "source": [
    "#####CREATE THE IMAGE and LABELS (MASK) LIST############\n",
    "images = []\n",
    "labels = []\n",
    "#create a mask for every image\n",
    "for i in images_string:\n",
    "    mask, img = create_mask(i, \"forest\")#dont forget to change the color\n",
    "    labels.append(mask)\n",
    "    images.append(img)\n",
    "\n",
    "\n",
    "print(len(images))#check to see if it everything is fine\n",
    "print(len(labels))#there should be the same number of images as labels\n",
    "print(np.shape(labels[0]))#check the dimensions of the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the images and all the masks, create one large vector containing all training samples. \n",
    " - The input vector has three columns for Y U V\n",
    " - The output has the label, ground or non-ground\n",
    " \n",
    " _Tip: modify the code to add several adjacent pixels as inputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1275000 1275000\n"
     ]
    }
   ],
   "source": [
    "# Convert images to training data (vector)\n",
    "\n",
    "X_vec = []\n",
    "y_vec = []\n",
    "\n",
    "maxfiles = 500\n",
    "samples_per_image = 75000\n",
    "\n",
    "for i in range(len(images)):\n",
    "    maxfiles -= 1\n",
    "    if maxfiles <=0:\n",
    "            break\n",
    "    img = images[i]\n",
    "    msk = labels[i]\n",
    "    h,w,d = img.shape\n",
    "    \n",
    "    #print('img=',f,'lbl=',lf,w,'x',h)\n",
    "\n",
    "     # Color space of RAW Bebop Images\n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img[:,:,1] = msk[:,:,0]\n",
    "\n",
    "    for i in range(0,samples_per_image):\n",
    "        \n",
    "        x = randrange(2,w-3)\n",
    "        y = randrange(4,h-2)\n",
    "\n",
    "        # Pixels\n",
    "        p = yuv[y,x]\n",
    "        # Ground thruth\n",
    "        m = int(msk[y,x,0])\n",
    "        if m < 127:\n",
    "            m = 0\n",
    "        else:\n",
    "            m=255\n",
    "\n",
    "        # Y, U, V\n",
    "        X_vec.append([int(p[0]),int(p[1]),int(p[2])])\n",
    "        y_vec.append([m])\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "print('Dataset',len(X_vec), len(y_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 20% of the data as test data and 80% as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1020000 1020000\n",
      "Test 255000 255000\n"
     ]
    }
   ],
   "source": [
    "# Split training data and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y_vec, test_size=0.2, stratify=y_vec, random_state=1)\n",
    "\n",
    "print('Train',len(X_train), len(y_train))\n",
    "print('Test',len(X_test), len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DecisionTreeClassifier, train and show the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.869\n"
     ]
    }
   ],
   "source": [
    "# Train our model\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Sensitivity:',round(score,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export\n",
    "\n",
    "The decision tree can be exported. Convert this to c-code to run it on the drone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- V <= 155.50\n",
      "|   |--- Y <= 144.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- Y >  144.50\n",
      "|   |   |--- class: 0\n",
      "|--- V >  155.50\n",
      "|   |--- U <= 96.50\n",
      "|   |   |--- class: 255\n",
      "|   |--- U >  96.50\n",
      "|   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export values in the form of a decision tree\n",
    "\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "text_representation = export_text(dt, feature_names=['Y','U','V'])\n",
    "\n",
    "print(text_representation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
